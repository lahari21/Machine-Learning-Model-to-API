{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3CtOWnhy5vx",
        "outputId": "bcf4332e-57c7-4950-d0d1-c00e9865a17d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.3)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting flask-bootstrap\n",
            "  Downloading Flask-Bootstrap-3.3.7.1.tar.gz (456 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-bootstrap) (2.2.5)\n",
            "Collecting dominate (from flask-bootstrap)\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visitor (from flask-bootstrap)\n",
            "  Downloading visitor-0.1.3.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-bootstrap) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-bootstrap) (2.1.3)\n",
            "Building wheels for collected packages: flask-bootstrap, visitor\n",
            "  Building wheel for flask-bootstrap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-bootstrap: filename=Flask_Bootstrap-3.3.7.1-py3-none-any.whl size=460118 sha256=7b07f60c94ad2cb90d16e0bc34beaa2b48ccc1cf01a0709da0069b6683562359\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/33/ad/26540e84a28334e5dfeda756df270f95353779f03bc5cf40d4\n",
            "  Building wheel for visitor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visitor: filename=visitor-0.1.3-py3-none-any.whl size=3926 sha256=70eb760efb1c5de2df126eb714e4beb9a5594ad3f6a1b5b8f8b8eea10e16d6f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/31/99/2ec5b4459cac4d801d6201d501a354366d180afc9f8bb2d333\n",
            "Successfully built flask-bootstrap visitor\n",
            "Installing collected packages: visitor, dominate, flask-bootstrap\n",
            "Successfully installed dominate-2.9.1 flask-bootstrap-3.3.7.1 visitor-0.1.3\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15963 sha256=5b42d3e370c135d3246fdcde5a4496541dc5b671d7708d21034c86767f4b1cb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install flask-bootstrap\n",
        "!pip install pyngrok==4.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jv11iEkhzEVW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import request, jsonify, Flask\n",
        "import random as r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sn63oMB7vxC",
        "outputId": "1b3b77ac-5725-4565-e0cc-aa8e1fa7d5ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken <insert your token>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cag7YsCz8p_7",
        "outputId": "6b370627-ebfc-4647-dd25-aac10a5c3edd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 136MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model dumped!\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import joblib\n",
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "joblib.dump(model, 'model.pkl')\n",
        "print(\"Model dumped!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WysFfq5a-YOq"
      },
      "outputs": [],
      "source": [
        "# Preprocess image\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "img = Image.open('/content/Machine-Learning-Model-to-API/statics/img.jpg')\n",
        "tfms = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
        "img = tfms(img).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvS-IgvV9bRo",
        "outputId": "81796d88-9278-4537-ff34-12f8bf3c9508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://5dc2-34-42-214-100.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [09/Jan/2024 17:12:00] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [09/Jan/2024 17:12:01] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [09/Jan/2024 17:12:03] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca           (45.03%)\n",
            "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens         (0.24%)\n",
            "limousine, limo                                                             (0.20%)\n",
            "soccer ball                                                                 (0.16%)\n",
            "Walker hound, Walker foxhound                                               (0.16%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [09/Jan/2024 17:12:10] \"POST /input HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "from flask import Flask, render_template\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import traceback\n",
        "\n",
        "app = Flask(__name__,static_folder='static')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello():\n",
        "    return render_template('hello.html')\n",
        "\n",
        "\n",
        "@app.route('/input', methods=['GET', 'POST'])\n",
        "def show_index():\n",
        "    img_path = '/content/Machine-Learning-Model-to-API/statics/img.jpg'\n",
        "    with open(img_path, \"rb\") as image_file:\n",
        "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    return render_template('index.html', img_data=encoded_string)\n",
        "\n",
        "@app.route('/predict', methods=['GET','POST'])\n",
        "def predict():\n",
        "    if model:\n",
        "        try:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                logits = model(img)\n",
        "            preds = torch.topk(logits, k=5).indices.squeeze(0).tolist()\n",
        "            labels_map = json.load(open('/content/Machine-Learning-Model-to-API/labels_map.txt'))\n",
        "            labels_map = [labels_map[str(i)] for i in range(1000)]\n",
        "            output ={}\n",
        "            for idx in preds:\n",
        "                label = labels_map[idx]\n",
        "                prob = torch.softmax(logits, dim=1)[0, idx].item()\n",
        "                print('{:<75} ({:.2f}%)'.format(label, prob*100))\n",
        "                output[label] = '({:.2f}%)'.format(prob*100)\n",
        "                output[prob] = '({:.2f}%)'.format(prob*100)\n",
        "            # return jsonify({'prediction': str(output)})\n",
        "            return render_template('predict.html', data =output)\n",
        "\n",
        "        except:\n",
        "\n",
        "            return jsonify({'trace': traceback.format_exc()})\n",
        "    else:\n",
        "        print ('Train the model first')\n",
        "        return ('No model here to use')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = joblib.load(\"/content/Machine-Learning-Model-to-API/model.pkl\") # Load \"model.pkl\"\n",
        "    print ('Model loaded')\n",
        "\n",
        "    app.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
